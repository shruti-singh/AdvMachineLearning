{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2A_CharRNNForTextGen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1QnAlbBO2YAjNb2YEz1ryxsw_oco7YSY1",
      "authorship_tag": "ABX9TyMYn6D2YKJeprOSoOgxWvyn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shruti-singh/AdvMachineLearning/blob/main/assignment1/Q2A_CharRNNForTextGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVcsJsxK76ni"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhCjNfpV9DXx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsGj_EX69Dai"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxn_bKhs9Dc_"
      },
      "source": [
        "# # Mount drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2p1Nvkf9Q-_",
        "outputId": "0c6e49f8-03fe-4b5d-91d4-961644741058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/drive/My Drive/Coursework/Sem3/AdvanceML/HW1/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Coursework/Sem3/AdvanceML/HW1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IOoRUT59UNn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsjQE7ss9qQp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmiNpZSL9rD1"
      },
      "source": [
        "**Load the abstract data of NeurIPS and ICLR papers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAObZzW69yIy"
      },
      "source": [
        "Dataset details in Q2B_1_TrainDistilBERTForTextGen.ipynb\n",
        "\n",
        "Dataset construction in Q2B_0_create_training_data_small.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLlU-Kg_9DhX"
      },
      "source": [
        "data_file_path = tf.keras.utils.get_file('/content/drive/My Drive/Coursework/Sem3/AdvanceML/HW1/training_data_paper_abstracts_neurips_iclr.txt', 'https://dummyurl.txt')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BEbl5wh-ZrF",
        "outputId": "0ed49c51-af14-4126-d581-0274bbb54dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "#Dataset\n",
        "!head -10 ./training_data_paper_abstracts_neurips_iclr.txt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving a Class of Non-Convex Min-Max Games Using Iterative First Order Methods\n",
            "Recent applications that arise in machine learning have surged significant interest in solving min-max saddle point games.\n",
            "This problem has been extensively studied in the convex-concave regime for which a global equilibrium solution can be computed efficiently.\n",
            "In this paper, we study the problem in the non-convex regime and show that an ε–first order stationary point of the game can be computed when one of the player’s objective can be optimized to global optimality efficiently.\n",
            "In particular, we first consider the case where the objective of one of the players satisfies the Polyak-Łojasiewicz (PL) condition.\n",
            "For such a game, we show that a simple multi-step gradient descent-ascent algorithm finds an ε–first order stationary point of the problem in Õ(ε−2) iterations.\n",
            "Then we show that our framework can also be applied to the case where the objective of the “max-player\" is concave.\n",
            "In this case, we propose a multi-step gradient descent-ascent algorithm that finds an ε–first order stationary point of the game in Õ(ε−3.5) iterations, which is the best known rate in the literature.\n",
            "We applied our algorithm to a fair classification problem of Fashion-MNIST dataset and observed that the proposed algorithm results in smoother training and better generalization.\n",
            "We discuss the application of TAP mean field methods known from the Statistical Mechanics of disordered systems to Bayesian classification models with Gaussian processes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmpJJYQb-zBQ",
        "outputId": "5525ee80-99f5-412b-8f14-ca26638a5365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "\n",
        "print(\"\\n\\n\\nDataset consists of research papers abstracts downloaded from NeurIPS (1987-2019) and ICLR (2013-2020). Data download script is attached separately.\\n\\n\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Dataset consists of research papers abstracts downloaded from NeurIPS (1987-2019) and ICLR (2013-2020). Data download script is attached separately.\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqqyXhYZ8_oH",
        "outputId": "4445117e-ff38-45ea-9b7c-8753d4d2f570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text = open(data_file_path, 'rb').read().decode(encoding='utf-8')\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 17142750 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nZW_9dH-HfG"
      },
      "source": [
        "char_vocab = sorted(set(text))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3wkGTm9-Yg9",
        "outputId": "e2e41555-86db-434f-9cc0-851040924610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Char vocab length: \", len(char_vocab))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Char vocab length:  384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmi5N0iC-Mx6",
        "outputId": "25359e5d-7c53-49a7-f265-4fed5c6e1e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(char_vocab[50:100])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp1vnRKn_UDg"
      },
      "source": [
        "As we can see, there are a lot of special characters in the research paper text, which are usually absent in the daily usage text/literature. \n",
        "Research papers contain some greek characters such as lambda etc, and all sorts of mathematical symbols, which makes text generation for research papers harder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNZtkDeq-M3Z"
      },
      "source": [
        "# Creating a vocan mapping\n",
        "char_idx_map = {u:i for i, u in enumerate(char_vocab)}\n",
        "idx_char_map = np.array(char_vocab)\n",
        "\n",
        "# To be fed into the model\n",
        "text_as_integers = np.array([char_idx_map[c] for c in text])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csgBOr7q-M6G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OSnawMwAgfF"
      },
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_integers)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqxIYK9r-M9O"
      },
      "source": [
        "# Truncate sequences\n",
        "seq_length = 512\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywRoqXfhA25N"
      },
      "source": [
        "For char level models, the output is one char left shifted version of input, as the goal is to predict the next character."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0nXMFqE-NCO"
      },
      "source": [
        "def convert_input_to_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(convert_input_to_target)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OETO4I1-NGo"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "issBqeJuBfVc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na_EhXd5BfYN"
      },
      "source": [
        "class CharLevelRNN:\n",
        "    def __init__(self, char_vocab):\n",
        "        self.vocab_size = len(char_vocab)\n",
        "        self.embedding_dim = 256\n",
        "        self.rnn_units = 1024\n",
        "        self.batch_size = BATCH_SIZE\n",
        "\n",
        "        self.model = None\n",
        "        self.epochs = 10\n",
        "        self.optimizer = 'adam'\n",
        "        return\n",
        "    \n",
        "    def loss(labels, logits):\n",
        "        return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "    \n",
        "    def train_model(self, dataset):\n",
        "        self.model = tf.keras.Sequential([tf.keras.layers.Embedding(self.vocab_size,  self.embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "                                     tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(self.rnn_units)),\n",
        "                                     tf.keras.layers.Dense(vocab_size)])\n",
        "        self.model.compile(optimizer=self.optimizer, loss=loss)\n",
        "        history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
        "        return\n",
        "    \n",
        "    def get_model_summary(self):\n",
        "        print(self.model.summary())\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3p8SqbxBfbO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1ZpHzZ1Bfep"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Wn4AzjBfiK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmoigSzl-Na-"
      },
      "source": [
        "**References**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C554wn8B-NAO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}