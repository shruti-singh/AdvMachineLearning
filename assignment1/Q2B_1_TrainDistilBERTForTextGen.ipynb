{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation using DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# set the device to be used as GPU, otherwise use the CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dataset Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We curate 9671 papers accepted at NeurIPS conference from 1987 to 2019. Source: https://papers.nips.cc/\n",
    "#### We curate 5213 papers submitted to ICLR conference from 2013 to 2020. Source: https://openreview.net/group?id=ICLR.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We create the training dataset by extracting sentences from the abstracts and the titles of the papers, using nltk.sentence_tokenize. \n",
    "#### For training, each line contains one sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving a Class of Non-Convex Min-Max Games Using Iterative First Order Methods\r\n",
      "Recent applications that arise in machine learning have surged significant interest in solving min-max saddle point games.\r\n",
      "This problem has been extensively studied in the convex-concave regime for which a global equilibrium solution can be computed efficiently.\r\n",
      "In this paper, we study the problem in the non-convex regime and show that an ε–first order stationary point of the game can be computed when one of the player’s objective can be optimized to global optimality efficiently.\r\n",
      "In particular, we first consider the case where the objective of one of the players satisfies the Polyak-Łojasiewicz (PL) condition.\r\n",
      "For such a game, we show that a simple multi-step gradient descent-ascent algorithm finds an ε–first order stationary point of the problem in Õ(ε−2) iterations.\r\n",
      "Then we show that our framework can also be applied to the case where the objective of the “max-player\" is concave.\r\n"
     ]
    }
   ],
   "source": [
    "!head -7 training_data_paper_abstracts_neurips_iclr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-kkz81OY6xH"
   },
   "source": [
    "## 1. Train DistilBERT tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses the same WordPiece tokenizer as BERT. BertTokenizerFast is the faster implementation by huggingface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "AQ24QuwcgzVC",
    "outputId": "33b5718e-a787-4a3a-f393-70b71f53edb9"
   },
   "outputs": [],
   "source": [
    "!mkdir DistilBERTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_file_path = glob.glob(\"training_data_paper_abstracts_neurips_iclr.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BertWordPieceTokenizer??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    handle_chinese_chars=False,\n",
    "    strip_accents=True,\n",
    "    lowercase=False,             # This might be helpful to retain entities such as MLP, LSTM, etc.\n",
    ")\n",
    "\n",
    "# Train the WP tokenizer on the data\n",
    "tokenizer.train(\n",
    "    training_file_path,\n",
    "    vocab_size=50000,\n",
    "    min_frequency=2,\n",
    "    show_progress=True,\n",
    "    special_tokens=[\"[UNK]\", \"[SEP]\", \"[CLS]\", \"[PAD]\", \"[MASK]\"],\n",
    "    limit_alphabet=1000,\n",
    "    wordpieces_prefix=\"##\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DistilBERTModel/vocab.txt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to the directory\n",
    "tokenizer.save_model(\"DistilBERTModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the tokenizer can be loaded from the vocab again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.implementations import BertWordPieceTokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "tokenizer = BertWordPieceTokenizer(\"./DistilBERTModel/vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hO5M3vrAhcuj"
   },
   "outputs": [],
   "source": [
    "# Adding the [SEP] and [CLS] topens\n",
    "\n",
    "tokenizer._tokenizer.post_processor = BertProcessing((\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")), \n",
    "                                                     (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")))\n",
    "tokenizer.enable_truncation(max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "E3Ye27nchfzq",
    "outputId": "f6eac5f6-cb21-46c7-fad0-9c35ea0175af"
   },
   "source": [
    "Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "X8ya5_7rhjKS",
    "outputId": "ed5ae488-ea77-4719-8b6c-4cd90b03f517"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'in',\n",
       " 'this',\n",
       " 'paper',\n",
       " ',',\n",
       " 'we',\n",
       " 'present',\n",
       " 'a',\n",
       " 'novel',\n",
       " 'method',\n",
       " 'to',\n",
       " 'train',\n",
       " 'lstm',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"In this paper, we present a novel method to train LSTM.\").tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQpUC_CDhnWW"
   },
   "source": [
    "## 2. Train LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0qQzgrBi1OX"
   },
   "source": [
    "Import predefined config of the DIstilBERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertConfig, DistilBertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistilBertConfig??\n",
    "# Contains 6 layers, 12 attention heads, gelu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DistilBertConfig(vocab_size=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastTokenizer Impl. Load from location DistilBERTModel.\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"./DistilBERTModel\", max_len=512, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = DistilBertForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert.embeddings.word_embeddings.weight\n",
      "distilbert.embeddings.position_embeddings.weight\n",
      "distilbert.embeddings.LayerNorm.weight\n",
      "distilbert.embeddings.LayerNorm.bias\n",
      "distilbert.transformer.layer.0.attention.q_lin.weight\n",
      "distilbert.transformer.layer.0.attention.q_lin.bias\n",
      "distilbert.transformer.layer.0.attention.k_lin.weight\n",
      "distilbert.transformer.layer.0.attention.k_lin.bias\n",
      "distilbert.transformer.layer.0.attention.v_lin.weight\n",
      "distilbert.transformer.layer.0.attention.v_lin.bias\n",
      "distilbert.transformer.layer.0.attention.out_lin.weight\n",
      "distilbert.transformer.layer.0.attention.out_lin.bias\n",
      "distilbert.transformer.layer.0.sa_layer_norm.weight\n",
      "distilbert.transformer.layer.0.sa_layer_norm.bias\n",
      "distilbert.transformer.layer.0.ffn.lin1.weight\n",
      "distilbert.transformer.layer.0.ffn.lin1.bias\n",
      "distilbert.transformer.layer.0.ffn.lin2.weight\n",
      "distilbert.transformer.layer.0.ffn.lin2.bias\n",
      "distilbert.transformer.layer.0.output_layer_norm.weight\n",
      "distilbert.transformer.layer.0.output_layer_norm.bias\n",
      "distilbert.transformer.layer.1.attention.q_lin.weight\n",
      "distilbert.transformer.layer.1.attention.q_lin.bias\n",
      "distilbert.transformer.layer.1.attention.k_lin.weight\n",
      "distilbert.transformer.layer.1.attention.k_lin.bias\n",
      "distilbert.transformer.layer.1.attention.v_lin.weight\n",
      "distilbert.transformer.layer.1.attention.v_lin.bias\n",
      "distilbert.transformer.layer.1.attention.out_lin.weight\n",
      "distilbert.transformer.layer.1.attention.out_lin.bias\n",
      "distilbert.transformer.layer.1.sa_layer_norm.weight\n",
      "distilbert.transformer.layer.1.sa_layer_norm.bias\n",
      "distilbert.transformer.layer.1.ffn.lin1.weight\n",
      "distilbert.transformer.layer.1.ffn.lin1.bias\n",
      "distilbert.transformer.layer.1.ffn.lin2.weight\n",
      "distilbert.transformer.layer.1.ffn.lin2.bias\n",
      "distilbert.transformer.layer.1.output_layer_norm.weight\n",
      "distilbert.transformer.layer.1.output_layer_norm.bias\n",
      "distilbert.transformer.layer.2.attention.q_lin.weight\n",
      "distilbert.transformer.layer.2.attention.q_lin.bias\n",
      "distilbert.transformer.layer.2.attention.k_lin.weight\n",
      "distilbert.transformer.layer.2.attention.k_lin.bias\n",
      "distilbert.transformer.layer.2.attention.v_lin.weight\n",
      "distilbert.transformer.layer.2.attention.v_lin.bias\n",
      "distilbert.transformer.layer.2.attention.out_lin.weight\n",
      "distilbert.transformer.layer.2.attention.out_lin.bias\n",
      "distilbert.transformer.layer.2.sa_layer_norm.weight\n",
      "distilbert.transformer.layer.2.sa_layer_norm.bias\n",
      "distilbert.transformer.layer.2.ffn.lin1.weight\n",
      "distilbert.transformer.layer.2.ffn.lin1.bias\n",
      "distilbert.transformer.layer.2.ffn.lin2.weight\n",
      "distilbert.transformer.layer.2.ffn.lin2.bias\n",
      "distilbert.transformer.layer.2.output_layer_norm.weight\n",
      "distilbert.transformer.layer.2.output_layer_norm.bias\n",
      "distilbert.transformer.layer.3.attention.q_lin.weight\n",
      "distilbert.transformer.layer.3.attention.q_lin.bias\n",
      "distilbert.transformer.layer.3.attention.k_lin.weight\n",
      "distilbert.transformer.layer.3.attention.k_lin.bias\n",
      "distilbert.transformer.layer.3.attention.v_lin.weight\n",
      "distilbert.transformer.layer.3.attention.v_lin.bias\n",
      "distilbert.transformer.layer.3.attention.out_lin.weight\n",
      "distilbert.transformer.layer.3.attention.out_lin.bias\n",
      "distilbert.transformer.layer.3.sa_layer_norm.weight\n",
      "distilbert.transformer.layer.3.sa_layer_norm.bias\n",
      "distilbert.transformer.layer.3.ffn.lin1.weight\n",
      "distilbert.transformer.layer.3.ffn.lin1.bias\n",
      "distilbert.transformer.layer.3.ffn.lin2.weight\n",
      "distilbert.transformer.layer.3.ffn.lin2.bias\n",
      "distilbert.transformer.layer.3.output_layer_norm.weight\n",
      "distilbert.transformer.layer.3.output_layer_norm.bias\n",
      "distilbert.transformer.layer.4.attention.q_lin.weight\n",
      "distilbert.transformer.layer.4.attention.q_lin.bias\n",
      "distilbert.transformer.layer.4.attention.k_lin.weight\n",
      "distilbert.transformer.layer.4.attention.k_lin.bias\n",
      "distilbert.transformer.layer.4.attention.v_lin.weight\n",
      "distilbert.transformer.layer.4.attention.v_lin.bias\n",
      "distilbert.transformer.layer.4.attention.out_lin.weight\n",
      "distilbert.transformer.layer.4.attention.out_lin.bias\n",
      "distilbert.transformer.layer.4.sa_layer_norm.weight\n",
      "distilbert.transformer.layer.4.sa_layer_norm.bias\n",
      "distilbert.transformer.layer.4.ffn.lin1.weight\n",
      "distilbert.transformer.layer.4.ffn.lin1.bias\n",
      "distilbert.transformer.layer.4.ffn.lin2.weight\n",
      "distilbert.transformer.layer.4.ffn.lin2.bias\n",
      "distilbert.transformer.layer.4.output_layer_norm.weight\n",
      "distilbert.transformer.layer.4.output_layer_norm.bias\n",
      "distilbert.transformer.layer.5.attention.q_lin.weight\n",
      "distilbert.transformer.layer.5.attention.q_lin.bias\n",
      "distilbert.transformer.layer.5.attention.k_lin.weight\n",
      "distilbert.transformer.layer.5.attention.k_lin.bias\n",
      "distilbert.transformer.layer.5.attention.v_lin.weight\n",
      "distilbert.transformer.layer.5.attention.v_lin.bias\n",
      "distilbert.transformer.layer.5.attention.out_lin.weight\n",
      "distilbert.transformer.layer.5.attention.out_lin.bias\n",
      "distilbert.transformer.layer.5.sa_layer_norm.weight\n",
      "distilbert.transformer.layer.5.sa_layer_norm.bias\n",
      "distilbert.transformer.layer.5.ffn.lin1.weight\n",
      "distilbert.transformer.layer.5.ffn.lin1.bias\n",
      "distilbert.transformer.layer.5.ffn.lin2.weight\n",
      "distilbert.transformer.layer.5.ffn.lin2.bias\n",
      "distilbert.transformer.layer.5.output_layer_norm.weight\n",
      "distilbert.transformer.layer.5.output_layer_norm.bias\n",
      "vocab_transform.weight\n",
      "vocab_transform.bias\n",
      "vocab_layer_norm.weight\n",
      "vocab_layer_norm.bias\n",
      "vocab_projector.bias\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters in DIstilBERT Model:  81964112\n"
     ]
    }
   ],
   "source": [
    "print(\"Total parameters in DIstilBERT Model: \", model.num_parameters())\n",
    "# BERT contains around 126 Million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling, LineByLineTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "GlvP_A-THEEl",
    "outputId": "bea74c67-7710-44b0-da04-2d86cdb776e5"
   },
   "outputs": [],
   "source": [
    "# We use our trained tokenizer on the data\n",
    "dataset = LineByLineTextDataset(tokenizer=tokenizer, file_path=\"./training_data_paper_abstracts_neurips_iclr.txt\",\n",
    "                                block_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "zTgWPa9Dipk2"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "YpvnFFmZJD-N",
    "outputId": "af403075-92df-4888-cc82-393b2015489b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/singh_shruti/.local/lib/python3.8/site-packages/transformers/trainer.py:263: FutureWarning: Passing `prediction_loss_only` as a keyword argument is deprecated and won't be possible in a future version. Use `args.prediction_loss_only` instead. Setting `args.prediction_loss_only=True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./DistilBERTModel\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_gpu_train_batch_size=64,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    prediction_loss_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135,
     "referenced_widgets": [
      "d7d569ee76b441bb9f86c083c95f248b",
      "534f4d8d1af54c0daacefdf9563350a0",
      "7fb8fc8cd4f3402fb6b60d63d19dcc64",
      "85ff70f3c2d3436c8a2dcff0b273f6df",
      "718e291f125e419888f47938bdf7eb7c",
      "47f3abba88ac4b8cb9fbafbc122ba289",
      "58ca1c60afd14712806c364ed857ccde",
      "40d923912b8e46f19ab6519c06314e47",
      "e6ea41f27906461a8a876679b6b3d6e0",
      "b03151b3edd7440ab9a3c5a2e68404c3",
      "a3238825fa804a4899503c2365bd8b2c",
      "b0143eb62d8e4830a1b6cb629220e9e6",
      "8be13c8f96bf47b3997aa5e46b8fafab",
      "17133825d1b8449cbae23cd51d2f49e0",
      "6c892f9572b54373ba14bc0c985af9dd",
      "f510e1412abf43fca8a7ac998da83862"
     ]
    },
    "id": "dmUXRqLfnm6h",
    "outputId": "905a6dd1-8ffc-4d04-c4c6-11e598444f82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef805e07163d45e388ddadd11e160850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f308bb62820c4781a5d0e3c513964ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Iteration'), FloatProgress(value=0.0, max=1849.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.013072265625, 'learning_rate': 4.549305931133946e-05, 'epoch': 0.2704164413196322, 'total_flos': 1175782399481856, 'step': 500}\n",
      "{'loss': 6.243638671875, 'learning_rate': 4.0986118622678924e-05, 'epoch': 0.5408328826392644, 'total_flos': 2326353949538304, 'step': 1000}\n",
      "{'loss': 6.0335234375, 'learning_rate': 3.647917793401839e-05, 'epoch': 0.8112493239588967, 'total_flos': 3487910002028544, 'step': 1500}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b01423cbd144dedaa6067c93f7a0dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Iteration'), FloatProgress(value=0.0, max=1849.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.791875, 'learning_rate': 3.197223724535785e-05, 'epoch': 1.0816657652785289, 'total_flos': 4621501210930176, 'step': 2000}\n",
      "{'loss': 5.55408984375, 'learning_rate': 2.746529655669732e-05, 'epoch': 1.3520822065981613, 'total_flos': 5785386355627008, 'step': 2500}\n",
      "{'loss': 5.3638828125, 'learning_rate': 2.2958355868036776e-05, 'epoch': 1.6224986479177934, 'total_flos': 6928404093121536, 'step': 3000}\n",
      "{'loss': 5.2172578125, 'learning_rate': 1.845141517937624e-05, 'epoch': 1.8929150892374258, 'total_flos': 8088071692471296, 'step': 3500}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b5eff734a24de6b99a9ceab44a47a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Iteration'), FloatProgress(value=0.0, max=1849.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.12032421875, 'learning_rate': 1.3944474490715703e-05, 'epoch': 2.1633315305570577, 'total_flos': 9255814396135296, 'step': 4000}\n",
      "{'loss': 5.0061328125, 'learning_rate': 9.437533802055165e-06, 'epoch': 2.43374797187669, 'total_flos': 10393827732807552, 'step': 4500}\n",
      "{'loss': 4.94041796875, 'learning_rate': 4.930593113394627e-06, 'epoch': 2.7041644131963225, 'total_flos': 11536436305454976, 'step': 5000}\n",
      "{'loss': 4.91706640625, 'learning_rate': 4.236524247340905e-07, 'epoch': 2.9745808545159544, 'total_flos': 12706773665048448, 'step': 5500}\n",
      "\n",
      "\n",
      "CPU times: user 47min 47s, sys: 5.57 s, total: 47min 52s\n",
      "Wall time: 47min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5547, training_loss=5.5580779165539935)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "QDNgPls7_l13"
   },
   "outputs": [],
   "source": [
    "# Saave to the same directory\n",
    "trainer.save_model(\"./DistilBERTModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generating Text using the DistilBERT LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "ltXgXyCbAJLY"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masked_word = pipeline(\"fill-mask\", model=\"./DistilBERTModel\", tokenizer=\"./DistilBERTModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt_sentence, words_to_gen=5):\n",
    "    \n",
    "    for i in range(words_to_gen):\n",
    "        pred_words = predict_masked_word(prompt_sentence + f\" {tokenizer.mask_token}\")\n",
    "        print(prompt_sentence + \": \")\n",
    "        potential_word_tokens = []\n",
    "        for w in pred_words:\n",
    "            potential_word_tokens.append(w[\"token_str\"])\n",
    "        print(\"Potential words - \", \" \".join(potential_word_tokens))\n",
    "        idx = np.random.randint(0, len(potential_word_tokens))\n",
    "        prompt_sentence = prompt_sentence + \" \" + potential_word_tokens[idx]\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"\\n\\n\", prompt_sentence)\n",
    "    \n",
    "    return prompt_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We present our: \n",
      "Potential words -  method algorithm model approach framework\n",
      "\n",
      "\n",
      "We present our framework: \n",
      "Potential words -  . algorithm for model of\n",
      "\n",
      "\n",
      "We present our framework for: \n",
      "Potential words -  learning . algorithms data Learning\n",
      "\n",
      "\n",
      "We present our framework for Learning: \n",
      "Potential words -  . algorithm algorithms method models\n",
      "\n",
      "\n",
      "We present our framework for Learning .: \n",
      "Potential words -  . algorithms algorithm learning models\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " We present our framework for Learning . algorithms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We present our framework for Learning . algorithms'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"We present our\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam optimization is: \n",
      "Potential words -  . based that learning ?\n",
      "\n",
      "\n",
      "Adam optimization is learning: \n",
      "Potential words -  . algorithms models problems algorithm\n",
      "\n",
      "\n",
      "Adam optimization is learning problems: \n",
      "Potential words -  . for in , and\n",
      "\n",
      "\n",
      "Adam optimization is learning problems ,: \n",
      "Potential words -  . learning and models algorithms\n",
      "\n",
      "\n",
      "Adam optimization is learning problems , algorithms: \n",
      "Potential words -  . learning algorithms and ,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Adam optimization is learning problems , algorithms algorithms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Adam optimization is learning problems , algorithms algorithms'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Adam optimization is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Furthermore, we leverage: \n",
      "Potential words -  . data models algorithms ?\n",
      "\n",
      "\n",
      "Furthermore, we leverage data: \n",
      "Potential words -  . data models sets ?\n",
      "\n",
      "\n",
      "Furthermore, we leverage data sets: \n",
      "Potential words -  . data and , from\n",
      "\n",
      "\n",
      "Furthermore, we leverage data sets from: \n",
      "Potential words -  data . training tasks models\n",
      "\n",
      "\n",
      "Furthermore, we leverage data sets from .: \n",
      "Potential words -  . data e g ,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Furthermore, we leverage data sets from . data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Furthermore, we leverage data sets from . data'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Furthermore, we leverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot learning: \n",
      "Potential words -  models algorithms methods learning problems\n",
      "\n",
      "\n",
      "Zero-shot learning models: \n",
      "Potential words -  are learning . have ,\n",
      "\n",
      "\n",
      "Zero-shot learning models ,: \n",
      "Potential words -  learning such . are models\n",
      "\n",
      "\n",
      "Zero-shot learning models , models: \n",
      "Potential words -  . are learning have such\n",
      "\n",
      "\n",
      "Zero-shot learning models , models are: \n",
      "Potential words -  learning models . used algorithms\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Zero-shot learning models , models are algorithms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Zero-shot learning models , models are algorithms'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Zero-shot learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We compare our results: \n",
      "Potential words -  . on and results of\n",
      "\n",
      "\n",
      "We compare our results on: \n",
      "Potential words -  datasets data experiments synthetic results\n",
      "\n",
      "\n",
      "We compare our results on synthetic: \n",
      "Potential words -  datasets . data results tasks\n",
      "\n",
      "\n",
      "We compare our results on synthetic tasks: \n",
      "Potential words -  . datasets data results and\n",
      "\n",
      "\n",
      "We compare our results on synthetic tasks data: \n",
      "Potential words -  . datasets data tasks and\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " We compare our results on synthetic tasks data .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We compare our results on synthetic tasks data .'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"We compare our results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We release our: \n",
      "Potential words -  method model algorithm approach .\n",
      "\n",
      "\n",
      "We release our approach: \n",
      "Potential words -  . on algorithm that for\n",
      "\n",
      "\n",
      "We release our approach for: \n",
      "Potential words -  learning . data algorithms results\n",
      "\n",
      "\n",
      "We release our approach for learning: \n",
      "Potential words -  . algorithms models algorithm learning\n",
      "\n",
      "\n",
      "We release our approach for learning .: \n",
      "Potential words -  . algorithms data models learning\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " We release our approach for learning . data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We release our approach for learning . data'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"We release our\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We propose a novel: \n",
      "Potential words -  model algorithm framework method .\n",
      "\n",
      "\n",
      "We propose a novel algorithm: \n",
      "Potential words -  . for that algorithm based\n",
      "\n",
      "\n",
      "We propose a novel algorithm based: \n",
      "Potential words -  . algorithm method model learning\n",
      "\n",
      "\n",
      "We propose a novel algorithm based model: \n",
      "Potential words -  . algorithm learning model that\n",
      "\n",
      "\n",
      "We propose a novel algorithm based model algorithm: \n",
      "Potential words -  . that for learning based\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " We propose a novel algorithm based model algorithm learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We propose a novel algorithm based model algorithm learning'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"We propose a novel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "UIvgZ3S6AO0z",
    "outputId": "5f3d2f00-abdc-44a9-9c1b-75e3ec328576"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The specific attention pattern can be : \n",
      "Potential words -  used . data learned information\n",
      "\n",
      "\n",
      "The specific attention pattern can be  data: \n",
      "Potential words -  . data , ? and\n",
      "\n",
      "\n",
      "The specific attention pattern can be  data and: \n",
      "Potential words -  . data images information training\n",
      "\n",
      "\n",
      "The specific attention pattern can be  data and images: \n",
      "Potential words -  . data , ? space\n",
      "\n",
      "\n",
      "The specific attention pattern can be  data and images ?: \n",
      "Potential words -  . , data ? )\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " The specific attention pattern can be  data and images ? ?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The specific attention pattern can be  data and images ? ?'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"The specific attention pattern can be \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the sentence classification task, we use: \n",
      "Potential words -  . data learning models algorithms\n",
      "\n",
      "\n",
      "For the sentence classification task, we use learning: \n",
      "Potential words -  . algorithms models methods problems\n",
      "\n",
      "\n",
      "For the sentence classification task, we use learning methods: \n",
      "Potential words -  . algorithms learning methods models\n",
      "\n",
      "\n",
      "For the sentence classification task, we use learning methods learning: \n",
      "Potential words -  . algorithms models methods problems\n",
      "\n",
      "\n",
      "For the sentence classification task, we use learning methods learning algorithms: \n",
      "Potential words -  . learning algorithms methods models\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " For the sentence classification task, we use learning methods learning algorithms algorithms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'For the sentence classification task, we use learning methods learning algorithms algorithms'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"For the sentence classification task, we use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We compare our results with previous: \n",
      "Potential words -  results . data performance datasets\n",
      "\n",
      "\n",
      "We compare our results with previous data: \n",
      "Potential words -  . data datasets results models\n",
      "\n",
      "\n",
      "We compare our results with previous data results: \n",
      "Potential words -  . on and demonstrate datasets\n",
      "\n",
      "\n",
      "We compare our results with previous data results demonstrate: \n",
      "Potential words -  . results experiments data that\n",
      "\n",
      "\n",
      "We compare our results with previous data results demonstrate .: \n",
      "Potential words -  . datasets data results performance\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " We compare our results with previous data results demonstrate . .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We compare our results with previous data results demonstrate . .'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"We compare our results with previous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that long range dependecies are not captured completely by our model. Some of the reasons/improvements:\n",
    "1. The model has around 81M parameters and we train it on a relatively small dataset of only 118,268 sentences. Including the full text of the paper might improve results. However, that will require more time to train.\n",
    "2. Another way to improve the model might be to use a pretrained model instead of training the LM from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "1. DistilBERT: https://huggingface.co/transformers/model_doc/distilbert.html\n",
    "2. Training models using transformers: https://huggingface.co/transformers/training.html\n",
    "3. https://huggingface.co/blog/how-to-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "01_how-to-train.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016d7c8318f742c1943464b08232a510": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04e7e6d291da49d5816dc98a2904e95c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39c23c6a972b419eb2eeeebafeaedc22",
      "placeholder": "​",
      "style": "IPY_MODEL_8388e9da9da4492c98c19235ca5fc1b5",
      "value": " 15228/15228 [2:46:46&lt;00:00,  1.52it/s]"
     }
    },
    "0989d41a4da24e9ebff377e02127642c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d295dd80550447d88da0f04ce36a22ff",
       "IPY_MODEL_04e7e6d291da49d5816dc98a2904e95c"
      ],
      "layout": "IPY_MODEL_42c6061ef7e44f179db5a6e3551c0f17"
     }
    },
    "17133825d1b8449cbae23cd51d2f49e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39c23c6a972b419eb2eeeebafeaedc22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40bf955ba0284e84b198da6be8654219": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "40d923912b8e46f19ab6519c06314e47": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42c6061ef7e44f179db5a6e3551c0f17": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47f3abba88ac4b8cb9fbafbc122ba289": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "534f4d8d1af54c0daacefdf9563350a0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58ca1c60afd14712806c364ed857ccde": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c892f9572b54373ba14bc0c985af9dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6feb10aeb43147e6aba028d065947ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "718e291f125e419888f47938bdf7eb7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7fb8fc8cd4f3402fb6b60d63d19dcc64": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Epoch:   0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47f3abba88ac4b8cb9fbafbc122ba289",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_718e291f125e419888f47938bdf7eb7c",
      "value": 0
     }
    },
    "837c9ddc3d594e088891874560c646b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Epoch: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe20a8dae6e84628b5076d02183090f5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40bf955ba0284e84b198da6be8654219",
      "value": 1
     }
    },
    "8388e9da9da4492c98c19235ca5fc1b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85ff70f3c2d3436c8a2dcff0b273f6df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_40d923912b8e46f19ab6519c06314e47",
      "placeholder": "​",
      "style": "IPY_MODEL_58ca1c60afd14712806c364ed857ccde",
      "value": " 0/1 [00:00&lt;?, ?it/s]"
     }
    },
    "8be13c8f96bf47b3997aa5e46b8fafab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "93b3f9eae3cb4e3e859cf456e3547c6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3238825fa804a4899503c2365bd8b2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Iteration:   0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17133825d1b8449cbae23cd51d2f49e0",
      "max": 15228,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8be13c8f96bf47b3997aa5e46b8fafab",
      "value": 55
     }
    },
    "a491e8caa0a048beb3b5259f14eb233f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a58a66392b644b1384661e850c077a6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_837c9ddc3d594e088891874560c646b8",
       "IPY_MODEL_dbf50873d62c4ba39321faefbed0cca5"
      ],
      "layout": "IPY_MODEL_a491e8caa0a048beb3b5259f14eb233f"
     }
    },
    "b0143eb62d8e4830a1b6cb629220e9e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f510e1412abf43fca8a7ac998da83862",
      "placeholder": "​",
      "style": "IPY_MODEL_6c892f9572b54373ba14bc0c985af9dd",
      "value": " 55/15228 [00:36&lt;2:44:29,  1.54it/s]"
     }
    },
    "b03151b3edd7440ab9a3c5a2e68404c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d295dd80550447d88da0f04ce36a22ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Iteration: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_016d7c8318f742c1943464b08232a510",
      "max": 15228,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7d8c3a4fecd40778e32966b29ea65a1",
      "value": 15228
     }
    },
    "d7d569ee76b441bb9f86c083c95f248b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7fb8fc8cd4f3402fb6b60d63d19dcc64",
       "IPY_MODEL_85ff70f3c2d3436c8a2dcff0b273f6df"
      ],
      "layout": "IPY_MODEL_534f4d8d1af54c0daacefdf9563350a0"
     }
    },
    "dbf50873d62c4ba39321faefbed0cca5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6feb10aeb43147e6aba028d065947ae8",
      "placeholder": "​",
      "style": "IPY_MODEL_93b3f9eae3cb4e3e859cf456e3547c6d",
      "value": " 1/1 [2:46:46&lt;00:00, 10006.17s/it]"
     }
    },
    "e6ea41f27906461a8a876679b6b3d6e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a3238825fa804a4899503c2365bd8b2c",
       "IPY_MODEL_b0143eb62d8e4830a1b6cb629220e9e6"
      ],
      "layout": "IPY_MODEL_b03151b3edd7440ab9a3c5a2e68404c3"
     }
    },
    "e7d8c3a4fecd40778e32966b29ea65a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f510e1412abf43fca8a7ac998da83862": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe20a8dae6e84628b5076d02183090f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
